<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>recourse on ÂàÄÂøÉÊ∞¥Êï≤Â≠ó„ÅÆÂú∞Êñπ</title>
    <link>https://nianze.tk/tags/recourse/</link>
    <description>Recent content in recourse on ÂàÄÂøÉÊ∞¥Êï≤Â≠ó„ÅÆÂú∞Êñπ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 31 May 2018 16:07:41 -0400</lastBuildDate>
    
        <atom:link href="https://nianze.tk/tags/recourse/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A simple archive for music generation</title>
      <link>https://nianze.tk/2018/05/music-generation-archive/</link>
      <pubDate>Thu, 31 May 2018 16:07:41 -0400</pubDate>
      
      <guid>https://nianze.tk/2018/05/music-generation-archive/</guid>
      <description>&lt;p&gt;A random collection of recent works on music generation.&lt;/p&gt;

&lt;!-- toc --&gt;

&lt;h1 id=&#34;papers&#34;&gt;Papers&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Melody Generation for Pop Music via Word Representation of Musical Properties&lt;/strong&gt; (2017.10) [&lt;a href=&#34;https://arxiv.org/abs/1710.11549&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;https://github.com/mil-tokyo/NeuralMelody&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generating Nontrivial Melodies for Music as a Service&lt;/strong&gt; (2017.10) [&lt;a href=&#34;https://arxiv.org/abs/1710.02280&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;https://composing.ai&#34;&gt;Page&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MuseGAN: Symbolic-domain Music Generation and Accompaniment with Multi-track Sequential Generative Adversarial Networks&lt;/strong&gt; (2017.9) [&lt;a href=&#34;https://arxiv.org/abs/1709.06298&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;https://salu133445.github.io/musegan/&#34;&gt;Page&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Similarity Embedding Network for Unsupervised Sequential Pattern Learning by Playing Music Puzzle Games&lt;/strong&gt; Ôºà2017.9Ôºâ[&lt;a href=&#34;https://arxiv.org/abs/1709.04384&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;https://remyhuang.github.io/DJnet&#34;&gt;Page&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A Tutorial on Deep Learning for Music Information Retrieval&lt;/strong&gt; (2017.9) [&lt;a href=&#34;https://arxiv.org/abs/1709.04396&#34;&gt;arXiv&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deep Learning Techniques for Music Generation - A Survey&lt;/strong&gt; (2017.9) &lt;a href=&#34;ËÆ∫ÊñáÁªºËø∞&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/1709.01620&#34;&gt;arXiv&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neural Translation of Musical Style&lt;/strong&gt; (2017.8) [&lt;a href=&#34;https://arxiv.org/abs/1708.03535&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;http://imanmalik.com/cs/2017/06/05/neural-style.html&#34;&gt;Page&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GLSR-VAE: Geodesic Latent Space Regularization for Variational AutoEncoder Architectures&lt;/strong&gt; (2017.7) [&lt;a href=&#34;https://arxiv.org/abs/1707.04588&#34;&gt;arXiv&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learning and Evaluating Musical Features with Deep Autoencoders&lt;/strong&gt; (2017.6) [&lt;a href=&#34;https://arxiv.org/abs/1706.04486&#34;&gt;arXiv&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models&lt;/strong&gt; (2017.5) [&lt;a href=&#34;https://arxiv.org/abs/1705.10843&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;https://github.com/gablg1/ORGAN&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation using 1D and 2D Conditions&lt;/strong&gt; - &lt;strong&gt;ISMIR 2017&lt;/strong&gt; (2017.3) [&lt;a href=&#34;https://arxiv.org/abs/1703.10847&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;https://richardyang40148.github.io/TheBlog/midinet_arxiv_demo.html&#34;&gt;Page&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Automatic Conversion of Pop Music into Chiptunes for 8-bit Pixel Art&lt;/strong&gt; - &lt;strong&gt;ICASSP 2017&lt;/strong&gt; (2017.2) [&lt;a href=&#34;http://mac.citi.sinica.edu.tw/~yang/pub/su17icassp_8bit.pdf&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LemonATsu/pop-to-8bit&#34;&gt;Code&lt;/a&gt;] [&lt;a href=&#34;https://lemonatsu.github.io&#34;&gt;Page&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DeepBach: a Steerable Model for Bach Chorales Generation&lt;/strong&gt; (2016.12) [&lt;a href=&#34;https://arxiv.org/abs/1612.01010&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;https://github.com/Ghadjeres/DeepBach&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;C-RNN-GAN: Continuous Recurrent Neural Networks with Adversarial Training&lt;/strong&gt; (2016.11) [&lt;a href=&#34;https://arxiv.org/abs/1611.09904&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;https://github.com/olofmogren/c-rnn-gan&#34;&gt;Code&lt;/a&gt;] üåü&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tuning Recurrent Neural Networks with Reinforcement Learning - ICLR 2017&lt;/strong&gt; (2016.11) [&lt;a href=&#34;https://arxiv.org/abs/1611.02796&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning&#34;&gt;Web&lt;/a&gt;] [&lt;a href=&#34;https://github.com/tensorflow/magenta/tree/master/magenta/models/rl_tuner&#34;&gt;Code&lt;/a&gt;] üåü&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient&lt;/strong&gt; - &lt;strong&gt;AAAI 2017&lt;/strong&gt; (2016.9) [&lt;a href=&#34;http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14344/14489&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/LantaoYu/SeqGAN&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Song From PI: A Musically Plausible Network for Pop Music Generation&lt;/strong&gt; - &lt;strong&gt;ICLR 2017&lt;/strong&gt; [&lt;a href=&#34;https://arxiv.org/abs/1611.03477&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;http://www.theregister.co.uk/2016/11/11/ai_pop_music_maker/&#34;&gt;Reports&lt;/a&gt;]üåü&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Text-based LSTM networks for Automatic Music Composition&lt;/strong&gt; (2016.4) [&lt;a href=&#34;https://arxiv.org/abs/1604.05358#&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;https://keunwoochoi.wordpress.com/2016/02/23/lstmetallica/&#34;&gt;Web&lt;/a&gt;] [&lt;a href=&#34;https://github.com/keunwoochoi/LSTMetallica&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Music Transcription Modelling and Composition Using Deep Learning&lt;/strong&gt; (2016.4) [&lt;a href=&#34;https://arxiv.org/abs/1604.08723&#34;&gt;arXiv&lt;/a&gt;] [&lt;a href=&#34;https://github.com/IraKorshunova/folk-rnn&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Composing A Melody with Long-short Term Memory (LSTM) Recurrent Neural Networks&lt;/strong&gt; (2016.2) [&lt;a href=&#34;http://konstilackner.github.io/LSTM-RNN-Melody-Composer-Website/&#34;&gt;Web&lt;/a&gt;] [&lt;a href=&#34;https://github.com/konstilackner/LSTM-RNN-Melody-Composer&#34;&gt;Code&lt;/a&gt;] [&lt;a href=&#34;http://konstilackner.github.io/LSTM-RNN-Melody-Composer-Website/Thesis_final01.pdf&#34;&gt;Paper&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neural Adaptive Sequential Monte Carlo - NIPS 2015&lt;/strong&gt; (2015) [&lt;a href=&#34;http://papers.nips.cc/paper/5961-neural-adaptive-sequential-monte-carlo.pdf&#34;&gt;Paper&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A Recurrent Latent Variable Model for Sequential Data - NIPS 2015&lt;/strong&gt; (2015) [&lt;a href=&#34;http://papers.nips.cc/paper/5653-a-recurrent-latent-variable-model-for-sequential-data.pdf&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/jych/nips2015_vrnn&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI Methods in Algorithmic Composition: A Comprehensive Survey&lt;/strong&gt; (2013) [&lt;a href=&#34;http://www.jair.org/media/3908/live-3908-7454-jair.pdf&#34;&gt;Paper&lt;/a&gt;] üåü&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modeling Temporal Dependencies in High-dimensional Sequences: Application to Polyphonic Music Generation and Transcription&lt;/strong&gt; (2012) [&lt;a href=&#34;https://arxiv.org/abs/1206.6392&#34;&gt;arXiv&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Towards Adaptive Music Generation By Reinforcement Learning of Musical Tension&lt;/strong&gt; (2010) [&lt;a href=&#34;https://ccrma.stanford.edu/~slegroux/affect/pubs/SMC2010.pdf&#34;&gt;Paper&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A First Look at Music Composition using LSTM Recurrent Neural Networks&lt;/strong&gt; (2002) [&lt;a href=&#34;http://www.iro.umontreal.ca/~eckdoug/blues/index.html&#34;&gt;Web&lt;/a&gt;] [&lt;a href=&#34;http://www.iro.umontreal.ca/~eckdoug/blues/IDSIA-07-02.pdf&#34;&gt;Paper&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;projects&#34;&gt;Projects&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Google Magenta&lt;/strong&gt; [&lt;a href=&#34;https://magenta.tensorflow.org/welcome-to-magenta&#34;&gt;Web&lt;/a&gt;] [&lt;a href=&#34;https://github.com/tensorflow/magenta&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deep Jazz&lt;/strong&gt;  [&lt;a href=&#34;https://deepjazz.io/&#34;&gt;Web&lt;/a&gt;] [&lt;a href=&#34;https://deepjazz.io/&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BachBot&lt;/strong&gt; [&lt;a href=&#34;http://bachbot.com/&#34;&gt;Web&lt;/a&gt;] [&lt;a href=&#34;https://github.com/feynmanliang/bachbot/&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WaveNet&lt;/strong&gt; [&lt;a href=&#34;https://deepmind.com/blog/wavenet-generative-model-raw-audio/&#34;&gt;Web&lt;/a&gt;]&lt;a href=&#34;not fully&#34;&gt;&lt;a href=&#34;https://github.com/ibab/tensorflow-wavenet&#34;&gt;Code&lt;/a&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GRUV&lt;/strong&gt; [&lt;a href=&#34;https://github.com/MattVitelli/GRUV&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kulitta&lt;/strong&gt; [&lt;a href=&#34;https://github.com/donya/Kulitta&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;applications&#34;&gt;Applications&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;AIVA&lt;/strong&gt;[&lt;a href=&#34;http://aiva.ai&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Google A.I. Duet&lt;/strong&gt; [&lt;a href=&#34;https://aiexperiments.withgoogle.com/ai-duet&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Infinite Drum Machine&lt;/strong&gt; [&lt;a href=&#34;https://aiexperiments.withgoogle.com/drum-machine&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Amper Music&lt;/strong&gt; [&lt;a href=&#34;https://www.ampermusic.com/app#/&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Intelligent Music System&lt;/strong&gt; [&lt;a href=&#34;http://120.52.72.53/www.intelligentmusicsystems.com/c3pr90ntc0td/vid/tempo_shifting.mp4&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unwind&lt;/strong&gt; [&lt;a href=&#34;http://unwind.ai&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tidalcycles&lt;/strong&gt; [&lt;a href=&#34;https://tidalcycles.org&#34;&gt;Link&lt;/a&gt;] [&lt;a href=&#34;https://www.youtube.com/watch?v=xoa3OT8ncX0&#34;&gt;Video&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jukedeck&lt;/strong&gt; [&lt;a href=&#34;https://www.jukedeck.com/&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;conferences-workshops&#34;&gt;Conferences&amp;amp;Workshops&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ACM MM&lt;/strong&gt; - ACM MultiMedia [&lt;a href=&#34;http://www.acmmm.org/2017&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ISMIR&lt;/strong&gt; - The International Society of Music Information Retrieval [&lt;a href=&#34;http://www.ismir.net/&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ICASSP&lt;/strong&gt; - Conference on Acoustics, Speech and Signal Processing [&lt;a href=&#34;http://www.ieee-icassp2017.org/&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DLM&lt;/strong&gt; - Deep Learning for Music Workshop [&lt;a href=&#34;http://dorienherremans.com/dlm2017/&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CSMC&lt;/strong&gt; - Conference on Computer Simulation of Musical  Creativity [&lt;a href=&#34;https://csmc2016.wordpress.com/&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CCRMA&lt;/strong&gt; - Center for Computer Research in Music and Acoustics (Stanford University) [&lt;a href=&#34;https://ccrma.stanford.edu/&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ICMC&lt;/strong&gt; - Internatonal Computer Music Conference [&lt;a href=&#34;http://www.icmc2017.com/&#34;&gt;Web&lt;/a&gt;] [&lt;a href=&#34;http://www.icmc2017.com/cn/page1.html&#34;&gt;Lists&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;blogs&#34;&gt;Blogs&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Neural Nets for Generating Music&lt;/strong&gt; [&lt;a href=&#34;https://medium.com/@kcimc/neural-nets-for-generating-music-f46dffac21c0&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generative Music with JavaScript &amp;amp; Web Audio&lt;/strong&gt; [&lt;a href=&#34;https://teropa.info/generative-music-slides/&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Current State Of AI: Artificial Intelligence In Music, Movies &amp;amp; More&lt;/strong&gt; (2017.7) [&lt;a href=&#34;http://www.hypebot.com/hypebot/2017/07/ai-today-the-current-state-of-artificial-intelligence.html&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Composing Music With Recurrent Neural Networks&lt;/strong&gt; (2015.8) [&lt;a href=&#34;http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/&#34;&gt;Web&lt;/a&gt;] [&lt;a href=&#34;https://github.com/hexahedria/biaxial-rnn-music-composition&#34;&gt;Code&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Analyzing deep learning tools for music generation&lt;/strong&gt; [&lt;a href=&#34;http://www.asimovinstitute.org/analyzing-deep-learning-tools-music/&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;COORD&lt;/strong&gt; [&lt;a href=&#34;http://www.coord.fm/home/&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;How evolved LSTMS improvise on a melogy you specify&lt;/strong&gt;[&lt;a href=&#34;https://www.sentient.ai/sentient-labs/ea/lstm-music/&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AI makes pop music in the style of any composer&lt;/strong&gt;[&lt;a href=&#34;http://www.flow-machines.com/ai-makes-pop-music/&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Richard Yang&amp;rsquo;s Blog&lt;/strong&gt;[&lt;a href=&#34;https://richardyang40148.github.io/TheBlog/index.html&#34;&gt;Blog&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Thousands of bird sounds visualized using machine learning&lt;/strong&gt;[&lt;a href=&#34;https://experiments.withgoogle.com/bird-sounds&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Music AI: Loop-in-the-Human&lt;/strong&gt;[&lt;a href=&#34;https://medium.com/@jayhardesty/music-ai-loop-in-the-human-1a15681e573e&#34;&gt;Web&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>